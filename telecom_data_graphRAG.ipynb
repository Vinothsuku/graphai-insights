{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neo4j\n",
      "  Downloading neo4j-5.28.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j) (2025.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading neo4j-5.28.1-py3-none-any.whl (312 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, neo4j, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed faiss-cpu-1.11.0 neo4j-5.28.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j faiss-cpu transformers torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import numpy as np\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neo4j configs\n",
    "NEO4J_URI=\"\"\n",
    "NEO4J_USERNAME=\"\"\n",
    "NEO4J_PASSWORD=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 4, Relationships: 10000\n"
     ]
    }
   ],
   "source": [
    "#get nodes and relationships\n",
    "def fetch_graph_data():\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (p:person) RETURN p.oid AS oid, p.name AS name\")\n",
    "        nodes = [{\"oid\": record[\"oid\"], \"name\": record[\"name\"]} for record in result]\n",
    "\n",
    "    # Fetch relationships (e.g., 'USES_DEVICE' between person and device)\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (p:person)-[r:USES_DEVICE]->(d:device) RETURN p.oid AS person_oid, d.oid AS device_oid, r.starttime AS starttime, r.endtime AS endtime\")\n",
    "        relationships = [{\"person_oid\": record[\"person_oid\"], \"device_oid\": record[\"device_oid\"], \"starttime\": record[\"starttime\"], \"endtime\": record[\"endtime\"]} for record in result]\n",
    "\n",
    "    return nodes, relationships\n",
    "\n",
    "nodes, relationships = fetch_graph_data()\n",
    "print(f\"Nodes: {len(nodes)}, Relationships: {len(relationships)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Labels:\n",
      "{'label': 'person'}\n",
      "{'label': 'device'}\n",
      "{'label': 'phonenumber'}\n",
      "{'label': 'celltower'}\n",
      "\n",
      "Relationship Types:\n",
      "{'relationshipType': 'USES_DEVICE'}\n",
      "{'relationshipType': 'CALLS'}\n",
      "{'relationshipType': 'CONNECTED_TO'}\n",
      "\n",
      "Node Properties:\n",
      "{'node_label': 'person', 'property_keys': [['oid', 'activities']]}\n",
      "{'node_label': 'device', 'property_keys': [['oid']]}\n",
      "{'node_label': 'phonenumber', 'property_keys': [['oid']]}\n",
      "{'node_label': 'celltower', 'property_keys': [['oid']]}\n",
      "\n",
      "Relationship Properties:\n",
      "{'rel_type': 'USES_DEVICE', 'property_keys': [['endtime', 'starttime']]}\n",
      "{'rel_type': 'CALLS', 'property_keys': [['endtime', 'starttime', 'duration']]}\n",
      "{'rel_type': 'CONNECTED_TO', 'property_keys': [['endtime', 'starttime']]}\n"
     ]
    }
   ],
   "source": [
    "def run_query(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        return [record.data() for record in result]\n",
    "\n",
    "# node labels\n",
    "node_labels = run_query(\"CALL db.labels()\")\n",
    "\n",
    "# relationship types\n",
    "rel_types = run_query(\"CALL db.relationshipTypes()\")\n",
    "\n",
    "# node property keys by label\n",
    "node_props = run_query(\"\"\"\n",
    "MATCH (n)\n",
    "WITH labels(n) AS label, keys(n) AS props\n",
    "UNWIND label AS l\n",
    "RETURN DISTINCT l AS node_label, collect(DISTINCT props) AS property_keys\n",
    "LIMIT 100\n",
    "\"\"\")\n",
    "\n",
    "# relationship property keys\n",
    "rel_props = run_query(\"\"\"\n",
    "MATCH ()-[r]->()\n",
    "RETURN DISTINCT type(r) AS rel_type, collect(DISTINCT keys(r)) AS property_keys\n",
    "LIMIT 100\n",
    "\"\"\")\n",
    "\n",
    "print(\"Node Labels:\")\n",
    "for item in node_labels:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nRelationship Types:\")\n",
    "for item in rel_types:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nNode Properties:\")\n",
    "for item in node_props:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nRelationship Properties:\")\n",
    "for item in rel_props:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_intent_with_llm(query):\n",
    "    prompt = f\"\"\"\n",
    "You are an intent classification model for a graph database with this schema:\n",
    "\n",
    "Node labels:\n",
    "- person(oid, activities)\n",
    "- device(oid)\n",
    "- phonenumber(oid)\n",
    "- celltower(oid)\n",
    "\n",
    "Relationship types:\n",
    "- USES_DEVICE(starttime, endtime)\n",
    "- CALLS(starttime, endtime, duration)\n",
    "- CONNECTED_TO(starttime, endtime)\n",
    "\n",
    "Identify the intent behind the query from the following categories:\n",
    "- get_devices_by_person\n",
    "- get_calls_by_person\n",
    "- get_activities_by_person\n",
    "- get_phonenumbers_by_person\n",
    "- get_activities_by_celltower\n",
    "- get_calls_between_people\n",
    "\n",
    "Only return the intent name.\n",
    "\n",
    "Query: \"{query}\"\n",
    "Intent:\n",
    "\"\"\"\n",
    "    from transformers import pipeline\n",
    "    classifier = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "    result = classifier(prompt, max_new_tokens=10)[0]['generated_text']\n",
    "    return result.strip().split(\"Intent:\")[-1].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2603295b487d401a8fab518a6a6573fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a2cf6f2a20484d820bde9768d9ee9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9bc68481514497903ac31614ac3d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965c3cf0b19a4f6dab9275ae530955ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ff5be69cc144028b408a55235c9273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d100e6f6bab4fffb8c5865132f2bc3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b039885a807b4e9688abdd9ddcec1ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified intent: - get_devices_by_person(\n"
     ]
    }
   ],
   "source": [
    "query = \"how many phone number did person 32 had\"\n",
    "intent = classify_intent_with_llm(query)\n",
    "print(f\"Identified intent: {intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating data for Spacy - custom NER training\n",
    "\n",
    "persons = [f\"person {i}\" for i in range(1, 50)]\n",
    "devices = [f\"device {i}\" for i in range(1, 20)]\n",
    "phonenumbers = [f\"phonenumber {i}\" for i in range(100, 150)]\n",
    "celltowers = [f\"celltower {i}\" for i in range(20, 40)]\n",
    "dates = [f\"2004-09-{str(i).zfill(2)}\" for i in range(1, 30)]\n",
    "\n",
    "templates = [\n",
    "    (\"Which devices did {person} use?\", \"PERSON\"),\n",
    "    (\"What is the phone number used by {person}?\", \"PERSON\"),\n",
    "    (\"Show me calls between {phone1} and {phone2}\", (\"PHONENUMBER\", \"PHONENUMBER\")),\n",
    "    (\"List activities for {person}\", \"PERSON\"),\n",
    "    (\"Which celltower was used at {date}?\", \"CELLTOWER\"),\n",
    "    (\"Who used {device}?\", \"DEVICE\"),\n",
    "    (\"Which phone numbers were connected to {celltower}?\", \"CELLTOWER\"),\n",
    "]\n",
    "\n",
    "TRAIN_DATA = []\n",
    "\n",
    "for _ in range(200):\n",
    "    template, label = random.choice(templates)\n",
    "    if label == \"PERSON\":\n",
    "        p = random.choice(persons)\n",
    "        sentence = template.format(person=p)\n",
    "        start = sentence.find(p)\n",
    "        end = start + len(p)\n",
    "        TRAIN_DATA.append((sentence, {\"entities\": [(start, end, \"PERSON\")]}))\n",
    "\n",
    "    elif label == \"DEVICE\":\n",
    "        d = random.choice(devices)\n",
    "        sentence = template.format(device=d)\n",
    "        start = sentence.find(d)\n",
    "        end = start + len(d)\n",
    "        TRAIN_DATA.append((sentence, {\"entities\": [(start, end, \"DEVICE\")]}))\n",
    "\n",
    "    elif label == \"CELLTOWER\":\n",
    "        c = random.choice(celltowers)\n",
    "        sentence = template.format(celltower=c, date=random.choice(dates))\n",
    "        start = sentence.find(c)\n",
    "        end = start + len(c)\n",
    "        TRAIN_DATA.append((sentence, {\"entities\": [(start, end, \"CELLTOWER\")]}))\n",
    "\n",
    "    elif isinstance(label, tuple) and label[0] == \"PHONENUMBER\":\n",
    "        p1 = random.choice(phonenumbers)\n",
    "        p2 = random.choice([x for x in phonenumbers if x != p1])\n",
    "        sentence = template.format(phone1=p1, phone2=p2)\n",
    "        s1, e1 = sentence.find(p1), sentence.find(p1) + len(p1)\n",
    "        s2, e2 = sentence.find(p2), sentence.find(p2) + len(p2)\n",
    "        TRAIN_DATA.append((sentence, {\"entities\": [(s1, e1, \"PHONENUMBER\"), (s2, e2, \"PHONENUMBER\")]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('List activities for person 2', {'entities': [(20, 28, 'PERSON')]}),\n",
       " ('What is the phone number used by person 20?',\n",
       "  {'entities': [(33, 42, 'PERSON')]}),\n",
       " ('Show me calls between phonenumber 105 and phonenumber 121',\n",
       "  {'entities': [(22, 37, 'PHONENUMBER'), (42, 57, 'PHONENUMBER')]})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - Losses: {'ner': np.float32(270.77023)}\n",
      "Iteration 2 - Losses: {'ner': np.float32(16.261087)}\n",
      "Iteration 3 - Losses: {'ner': np.float32(0.25170982)}\n",
      "Iteration 4 - Losses: {'ner': np.float32(0.17620875)}\n",
      "Iteration 5 - Losses: {'ner': np.float32(0.0016202566)}\n",
      "Iteration 6 - Losses: {'ner': np.float32(5.369323e-05)}\n",
      "Iteration 7 - Losses: {'ner': np.float32(2.6668426e-06)}\n",
      "Iteration 8 - Losses: {'ner': np.float32(9.05726)}\n",
      "Iteration 9 - Losses: {'ner': np.float32(0.00040915608)}\n",
      "Iteration 10 - Losses: {'ner': np.float32(0.02383003)}\n",
      "Model saved to custom_ner_model\n"
     ]
    }
   ],
   "source": [
    "#Training custom NER model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\")\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(10):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            for text, annotations in batch:\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                nlp.update([example], drop=0.3, losses=losses)\n",
    "        print(f\"Iteration {itn+1} - Losses: {losses}\")\n",
    "\n",
    "output_dir = \"custom_ner_model\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: [('person 123', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "#Checking entity extraction from custom ner model\n",
    "nlp = spacy.load(\"custom_ner_model\")\n",
    "text = \"Which devices did person 123 use?\"\n",
    "doc = nlp(text)\n",
    "print(\"Entities:\", [(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: [('phonenumber 2233', 'PHONENUMBER'), ('device nokia', 'DEVICE'), ('celltower 26', 'CELLTOWER')]\n"
     ]
    }
   ],
   "source": [
    "text = \"is phonenumber 2233 is from device nokia connected to celltower 26\"\n",
    "doc = nlp(text)\n",
    "print(\"Entities:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0ab516444b4f4989cf0d270573567a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cf6b486cd94a278a4a1ce3a301e23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd43afdc255d4bc6aa9524069f78edb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe9b3b89c244ccf831b9965e215d380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d06bf8652a64a1696214ee4d56beb92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3cf9374c5c4316904b9ff410cabe44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3c2ea0fe44479caea0394024167a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4cb6314432435b80a65e5e3bb7fce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cc5ba1b8ed4132b98c737458eb1601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e1477cab6b476a83e2dad349b13d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4628f903578413ab6a4ebb22ad33451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Embed graph data from neo4j using sentence transformer\n",
    "#Triplets - (subject, predicate, object)\n",
    "#neo4j - (node1)-[relationship]->(node2)\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "triplets = []\n",
    "metadata = []\n",
    "\n",
    "def build_sentence(row, rel_type):\n",
    "    if rel_type == \"USES_DEVICE\":\n",
    "        return f\"person {row['person']} used device {row['device']} from {row['starttime']} to {row['endtime']}\"\n",
    "    elif rel_type == \"CALLS\":\n",
    "        return f\"phonenumber {row['src']} called phonenumber {row['dst']} from {row['starttime']} to {row['endtime']} lasting {row['duration']} seconds\"\n",
    "    elif rel_type == \"CONNECTED_TO\":\n",
    "        return f\"phonenumber {row['phonenumber']} connected to celltower {row['celltower']} from {row['starttime']} to {row['endtime']}\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "\n",
    "    query1 = \"\"\"\n",
    "        MATCH (p:person)-[r:USES_DEVICE]->(d:device)\n",
    "        RETURN p.oid AS person, d.oid AS device, r.starttime AS starttime, r.endtime AS endtime\n",
    "    \"\"\"\n",
    "    for row in session.run(query1):\n",
    "        sent = build_sentence(row, \"USES_DEVICE\")\n",
    "        triplets.append(sent)\n",
    "        metadata.append(dict(row))\n",
    "\n",
    "    query2 = \"\"\"\n",
    "        MATCH (a:phonenumber)-[r:CALLS]->(b:phonenumber)\n",
    "        RETURN a.oid AS src, b.oid AS dst, r.starttime AS starttime, r.endtime AS endtime, r.duration AS duration\n",
    "    \"\"\"\n",
    "    for row in session.run(query2):\n",
    "        sent = build_sentence(row, \"CALLS\")\n",
    "        triplets.append(sent)\n",
    "        metadata.append(dict(row))\n",
    "\n",
    "    query3 = \"\"\"\n",
    "        MATCH (p:phonenumber)-[r:CONNECTED_TO]->(c:celltower)\n",
    "        RETURN p.oid AS phonenumber, c.oid AS celltower, r.starttime AS starttime, r.endtime AS endtime\n",
    "    \"\"\"\n",
    "    for row in session.run(query3):\n",
    "        sent = build_sentence(row, \"CONNECTED_TO\")\n",
    "        triplets.append(sent)\n",
    "        metadata.append(dict(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete. Total triplets: 10000\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(triplets, convert_to_numpy=True)\n",
    "\n",
    "#faiss index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "faiss.write_index(index, \"graph_triplets.index\")\n",
    "np.save(\"triplet_texts.npy\", triplets)\n",
    "\n",
    "#Saving embeddings\n",
    "np.save(\"graph_embeddings.npy\", embeddings)\n",
    "with open(\"graph_metadata.json\", \"w\") as f:\n",
    "    import json\n",
    "    json.dump(metadata, f)\n",
    "\n",
    "print(\"Embedding complete. Total triplets:\", len(triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load TinyLlama\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "\n",
    "#Load SentenceTransformer for embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "#Load FAISS index and triplets\n",
    "faiss_index = faiss.read_index(\"graph_triplets.index\")\n",
    "with open(\"triplet_texts.npy\", \"rb\") as f:\n",
    "    triplet_texts = np.load(f, allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_embedding(query):\n",
    "    return embedding_model.encode([query]).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_faiss_index(query_embedding, top_k=10, entity_filter=None):\n",
    "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
    "    triplets = [triplet_texts[i] for i in indices[0]]\n",
    "\n",
    "    if entity_filter:\n",
    "        extended_filters = set()\n",
    "        for label, value in entity_filter.items() if isinstance(entity_filter, dict) else []:\n",
    "            extended_filters.add(str(value).lower())\n",
    "            extended_filters.add(f\"{label.lower()} {value}\".lower())\n",
    "        if not extended_filters and isinstance(entity_filter, list):\n",
    "            extended_filters = set(str(v).lower() for v in entity_filter)\n",
    "\n",
    "        def relevance_score(triplet):\n",
    "            score = 0\n",
    "            triplet_lower = triplet.lower()\n",
    "            for f in extended_filters:\n",
    "                if f in triplet_lower:\n",
    "                    score += 2 if ' ' in f else 1\n",
    "            return score\n",
    "\n",
    "        scored = sorted(triplets, key=relevance_score, reverse=True)\n",
    "        return scored[:top_k]\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entity_dict = {}\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ not in entity_dict:\n",
    "            entity_dict[ent.label_] = ent.text.strip()\n",
    "        else:\n",
    "            if isinstance(entity_dict[ent.label_], list):\n",
    "                entity_dict[ent.label_].append(ent.text.strip())\n",
    "            else:\n",
    "                entity_dict[ent.label_] = [entity_dict[ent.label_], ent.text.strip()]\n",
    "    return entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate cypher query - using few shot examples\n",
    "def generate_cypher_query(query, intent, entities, triplets):\n",
    "    # Few-shot examples\n",
    "    examples = \"\"\"\n",
    "Example 1:\n",
    "Query: Which devices did person 123 use?\n",
    "Intent: get_devices_by_person\n",
    "Entities: PERSON=123\n",
    "Graph context:\n",
    "- person 123 used device 10 from 2004-09-01 to 2004-09-10\n",
    "- person 123 used device 12 from 2004-09-11 to 2004-09-12\n",
    "Cypher:\n",
    "MATCH (p:person {oid: '123'})-[:USES_DEVICE]->(d:device)\n",
    "RETURN d\n",
    "\n",
    "Example 2:\n",
    "Query: What phone numbers did person 456 call?\n",
    "Intent: get_calls_by_person\n",
    "Entities: PERSON=456\n",
    "Graph context:\n",
    "- person 456 called phonenumber 789 from 2004-09-01 to 2004-09-10\n",
    "Cypher:\n",
    "MATCH (p:person {oid: '456'})-[:CALLS]->(ph:phonenumber)\n",
    "RETURN ph\n",
    "\n",
    "Example 3:\n",
    "Query: What activities are logged for person 789?\n",
    "Intent: get_activities_by_person\n",
    "Entities: PERSON=789\n",
    "Graph context:\n",
    "- person 789 used device 3 from 2004-09-05 to 2004-09-08\n",
    "Cypher:\n",
    "MATCH (p:person {oid: '789'})\n",
    "RETURN p.activities\n",
    "\n",
    "Example 4:\n",
    "Query: How many devices did person 94 use?\n",
    "Intent: count_devices_by_person\n",
    "Entities: PERSON=94\n",
    "Graph context:\n",
    "- person 94 used device 5 from 2004-09-01 to 2004-09-10\n",
    "Cypher:\n",
    "MATCH (p:person {oid: 94})-[:USES_DEVICE]->(d:device)\n",
    "RETURN COUNT(d) AS device_count\n",
    "\"\"\"\n",
    "\n",
    "    facts = \"\\n\".join(f\"- {t}\" for t in triplets[:5])\n",
    "    normalized_entities = {k: v.split()[-1] for k, v in entities.items()}\n",
    "    entity_context = \", \".join([f\"{k}={v}\" for k, v in normalized_entities.items()])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "{examples}\n",
    "\n",
    "### NEW QUERY ###\n",
    "Query: {query}\n",
    "Intent: {intent}\n",
    "Entities: {entity_context}\n",
    "Graph context:\n",
    "{facts}\n",
    "Cypher:\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=100,\n",
    "        #do_sample=False,\n",
    "        temperature=0.5,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    if \"Cypher:\" in decoded:\n",
    "        decoded = decoded.split(\"Cypher:\")[-1].strip()\n",
    "\n",
    "    cypher_lines = decoded.splitlines()\n",
    "    for i, line in enumerate(cypher_lines):\n",
    "        if \"MATCH\" in line:\n",
    "            return \"\\n\".join(cypher_lines[i:]).strip()\n",
    "\n",
    "    return decoded.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what devices were used by person 94\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'- get_devices_by_person('"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent = classify_intent_with_llm(query)\n",
    "intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PERSON': 'person 94'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = extract_entities(query)\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = get_query_embedding(query)\n",
    "#query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person 94 used device 93 from 2004-11-01T12:42:42 to 2004-11-01T12:42:42',\n",
       " 'person 94 used device 93 from 2004-07-23T16:12:42 to 2004-07-23T16:19:41',\n",
       " 'person 94 used device 238 from 2004-10-11T18:32:29 to 2004-10-11T18:32:29',\n",
       " 'person 94 used device 90 from 2004-11-16T22:26:18 to 2004-11-16T22:26:18',\n",
       " 'person 94 used device 90 from 2004-09-29T19:38:16 to 2004-09-29T19:48:43',\n",
       " 'person 94 used device 90 from 2004-11-18T19:09:22 to 2004-11-18T19:19:48',\n",
       " 'person 94 used device 66 from 2004-11-18T17:37:22 to 2004-11-18T17:37:22',\n",
       " 'person 94 used device 162 from 2004-12-20T09:19:20 to 2004-12-20T09:19:20',\n",
       " 'person 94 used device 93 from 2004-07-23T16:40:11 to 2004-07-23T17:44:48',\n",
       " 'person 94 used device 93 from 2004-07-23T14:24:11 to 2004-07-23T15:55:44']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_context = search_faiss_index(query_embedding, top_k=10,entity_filter=entities)\n",
    "triplet_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_query = generate_cypher_query(query, intent, entities, triplet_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Cypher:\n",
      "MATCH (p:person {oid: '94'})-[:USES_DEVICE]->(d:device)\n",
      "RETURN d\n",
      "```\n",
      "\n",
      "In this example, the `get_devices_by_person` query is used to retrieve the devices used by person 94. The `get_devices_by_person` query returns a list of devices, which can be used to filter the results of the `get_calls_by\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nGenerated Cypher:\\n{cypher_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
