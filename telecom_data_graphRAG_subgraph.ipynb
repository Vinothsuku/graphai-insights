{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGqjZK3HrTF5",
    "outputId": "7e7bd6cc-beaa-4060-fb6e-c07e531ca8a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neo4j\n",
      "  Downloading neo4j-5.28.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j) (2025.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading neo4j-5.28.1-py3-none-any.whl (312 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, neo4j, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed faiss-cpu-1.11.0 neo4j-5.28.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j faiss-cpu transformers torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3qyEisKDow_d"
   },
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import numpy as np\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jD8iIUv_TDZ7"
   },
   "outputs": [],
   "source": [
    "#neo4j configs\n",
    "NEO4J_URI=\"\"\n",
    "NEO4J_USERNAME=\"\"\n",
    "NEO4J_PASSWORD=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hq3NaTQoovMs"
   },
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUQ1oQc1owk9",
    "outputId": "e9dc3ea1-2c9a-4fa8-9aa1-42b7e31bf87c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 4, Relationships: 10000\n"
     ]
    }
   ],
   "source": [
    "#get nodes and relationships from neo4j\n",
    "def fetch_graph_data():\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (p:person) RETURN p.oid AS oid, p.name AS name\")\n",
    "        nodes = [{\"oid\": record[\"oid\"], \"name\": record[\"name\"]} for record in result]\n",
    "\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (p:person)-[r:USES_DEVICE]->(d:device) RETURN p.oid AS person_oid, d.oid AS device_oid, r.starttime AS starttime, r.endtime AS endtime\")\n",
    "        relationships = [{\"person_oid\": record[\"person_oid\"], \"device_oid\": record[\"device_oid\"], \"starttime\": record[\"starttime\"], \"endtime\": record[\"endtime\"]} for record in result]\n",
    "\n",
    "    return nodes, relationships\n",
    "\n",
    "nodes, relationships = fetch_graph_data()\n",
    "print(f\"Nodes: {len(nodes)}, Relationships: {len(relationships)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbdxdODEovPK",
    "outputId": "6411dff2-c06c-4ef9-c7a8-054e77031ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Labels:\n",
      "{'label': 'person'}\n",
      "{'label': 'device'}\n",
      "{'label': 'phonenumber'}\n",
      "{'label': 'celltower'}\n",
      "\n",
      "Relationship Types:\n",
      "{'relationshipType': 'USES_DEVICE'}\n",
      "{'relationshipType': 'CALLS'}\n",
      "{'relationshipType': 'CONNECTED_TO'}\n",
      "\n",
      "Node Properties:\n",
      "{'node_label': 'person', 'property_keys': [['oid', 'activities']]}\n",
      "{'node_label': 'device', 'property_keys': [['oid']]}\n",
      "{'node_label': 'phonenumber', 'property_keys': [['oid']]}\n",
      "{'node_label': 'celltower', 'property_keys': [['oid']]}\n",
      "\n",
      "Relationship Properties:\n",
      "{'rel_type': 'USES_DEVICE', 'property_keys': [['endtime', 'starttime']]}\n",
      "{'rel_type': 'CALLS', 'property_keys': [['endtime', 'starttime', 'duration']]}\n",
      "{'rel_type': 'CONNECTED_TO', 'property_keys': [['endtime', 'starttime']]}\n"
     ]
    }
   ],
   "source": [
    "def run_query(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        return [record.data() for record in result]\n",
    "\n",
    "#node labels\n",
    "node_labels = run_query(\"CALL db.labels()\")\n",
    "\n",
    "#relationship types\n",
    "rel_types = run_query(\"CALL db.relationshipTypes()\")\n",
    "\n",
    "#node property keys by label\n",
    "node_props = run_query(\"\"\"\n",
    "MATCH (n)\n",
    "WITH labels(n) AS label, keys(n) AS props\n",
    "UNWIND label AS l\n",
    "RETURN DISTINCT l AS node_label, collect(DISTINCT props) AS property_keys\n",
    "LIMIT 100\n",
    "\"\"\")\n",
    "\n",
    "#relationship property keys\n",
    "rel_props = run_query(\"\"\"\n",
    "MATCH ()-[r]->()\n",
    "RETURN DISTINCT type(r) AS rel_type, collect(DISTINCT keys(r)) AS property_keys\n",
    "LIMIT 100\n",
    "\"\"\")\n",
    "\n",
    "print(\"Node Labels:\")\n",
    "for item in node_labels:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nRelationship Types:\")\n",
    "for item in rel_types:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nNode Properties:\")\n",
    "for item in node_props:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nRelationship Properties:\")\n",
    "for item in rel_props:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390,
     "referenced_widgets": [
      "bc80c49fd1054d2a99b735d520166491",
      "0ace766ffaad4283827741f3bf6cc808",
      "66073bb3f08b44afadd67e2efa91c924",
      "1116330f05bf432f976e87d594bc2198",
      "513cdadb8b4e411a9f3b737f5d66e51b",
      "d0f38e233db84c40a977abd2261d3e31",
      "cd1cc1e153ac441da996bcb1d0404ac4",
      "8672b37c874440bea529ed89eea3c924",
      "ac0fedb5255440589a6614b7f19afbc2",
      "ce495aa2bb694b5188b0190521ac1856",
      "b1f0e9eeee3246d2aae3cc23347ae2cc",
      "60a9bcb5924b445e9f7fd415a2614c36",
      "7c993c898f2242ad8a8460e57a5ba9d1",
      "7561f833fa294567a3f8fe102e4d8091",
      "13fe0a758f80431dba7bbeaa8b930170",
      "cab1a9c9dcf64a64a644b6f2e0fa37d5",
      "7180a0686aa24993acba7336c9ac4cea",
      "b1f15ec9d2544d41bbf3f40e3db1dd49",
      "4678bccfbd884697a4a4f26099e90bce",
      "7819a26d24294a35869846279a29b115",
      "c0f76099d9f54dcfb709edbf0e96185d",
      "e1ddadcc175240b1b323ca4d9aaf03f8",
      "640d911699434a9986befc9ff4178302",
      "ae41878e6e5a4ecc8579ad8dbcaa3adf",
      "59efe6e172904f9f9fc2c0924deb1cd9",
      "04da09dd7240416888c3b405e6187a3b",
      "834abf984ed14a9db6172f636a12b728",
      "578fc3ec3a9f4c4ba0f37ec1d89adf7e",
      "8726a71890bc4b0ca1accc2f3a631e5b",
      "5d3e2d01598148cfb47c0f4a9a08b5e8",
      "96e304849ee7418cbce850fe3bc549c8",
      "a9f8b80f53834400944c1cd63eb6e56b",
      "2eace364976a474f9e8a71f499797730",
      "2db2caecb9bc4fe0b7015e06cdddd7b6",
      "9c8466cf0cad4f27ba67be1bed3c1d9f",
      "52bc61afa46a4fbca4975b0a136cc67c",
      "d5a63ed8def04ec18047bc982c5b60e2",
      "6f97136e7f4d4904b8f7bb9c1db1a7d9",
      "3f9d8a7e07cf4b8f90f475bca5663d86",
      "2938dd4b8b814a29982c65dbf804293a",
      "6ad033598b78457ba9fe317d100bdc92",
      "23f44ec26293436a8e193ae8a6cc56ed",
      "9bce0f0ef8d74884a45e7e56e96c228e",
      "87bcb4db9ea444b38053808c94f3f38f",
      "b6f37edb439e43fc9f7afe01940c776b",
      "85fbbcdc92fe46039e384cbcd418fd61",
      "3b9f63e7631e454188644b1517acb944",
      "4e8bd4cd3545455a95bdcc79b075ec67",
      "8e6d5691d7d142a48e8c10f778316036",
      "d25cac5a70b442b7bc7371a478ca079a",
      "43bd2d66580d488096c69f19687b4da9",
      "556a1c4a9d65438abff8be7a7911eff5",
      "5e5246840d6041599a74e0bf8730bccd",
      "240292ce4b2541eeb5f7bf6027190399",
      "ea0722b8e2124ec6b5effbb479dd7785",
      "8254ee3405a84b18a356e17dd9d18fb3",
      "19dec5330bb2449784d7034ea9c5cd59",
      "9f599693bbca49e3a16871dd1135d75b",
      "3018507a15144c36b265b34ef8c9bc58",
      "f8f665c444e1484791388cb16e810835",
      "e098c2440caa4b6793c6b5662e6e72f7",
      "cf7c01a501cc4005bfd60b5e6552e72b",
      "56cad2ab7802406e95bdc9380fe5baa9",
      "5be8c605644449d3baa6771dea15216e",
      "1a44f045fb2a4556a5962764e0ff781a",
      "9d9e162d84914a41bdb6f1ee8f3a774d"
     ]
    },
    "id": "d1hEtHHCovSC",
    "outputId": "f85565e7-cc30-4333-d7c8-e3a3d8902cd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc80c49fd1054d2a99b735d520166491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a9bcb5924b445e9f7fd415a2614c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640d911699434a9986befc9ff4178302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db2caecb9bc4fe0b7015e06cdddd7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f37edb439e43fc9f7afe01940c776b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8254ee3405a84b18a356e17dd9d18fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "#get intents (multiple if relevant) and entities\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "ner_model = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "intent_labels = [\n",
    "    \"get_devices_by_person\",\n",
    "    \"get_calls_by_person\",\n",
    "    \"get_activities_by_person\",\n",
    "    \"get_phonenumbers_by_person\",\n",
    "    \"get_activities_by_celltower\",\n",
    "    \"get_calls_between_people\"\n",
    "]\n",
    "\n",
    "intent_keywords = {\n",
    "    \"get_devices_by_person\": [\"device\", \"devices\", \"used\"],\n",
    "    \"get_calls_by_person\": [\"call\", \"calls\", \"called\"],\n",
    "    \"get_activities_by_person\": [\"activity\", \"activities\", \"did\"],\n",
    "    \"get_phonenumbers_by_person\": [\"phone number\", \"phone numbers\", \"number\"],\n",
    "    \"get_activities_by_celltower\": [\"celltower\", \"tower\", \"connected\"],\n",
    "    \"get_calls_between_people\": [\"between\", \"call between\", \"calls between\"]\n",
    "}\n",
    "\n",
    "intent_to_entity_label = {\n",
    "    \"get_devices_by_person\": [\"person\"],\n",
    "    \"get_calls_by_person\": [\"person\"],\n",
    "    \"get_activities_by_person\": [\"person\"],\n",
    "    \"get_phonenumbers_by_person\": [\"person\"],\n",
    "    \"get_activities_by_celltower\": [\"celltower\"],\n",
    "    \"get_calls_between_people\": [\"person\"]\n",
    "}\n",
    "\n",
    "def classify_intents_and_entities(query):\n",
    "    result = classifier(query, candidate_labels=intent_labels, multi_label=True)\n",
    "    predicted_intents = [\n",
    "        (label, score) for label, score in zip(result[\"labels\"], result[\"scores\"])\n",
    "        if score >= 0.6\n",
    "    ]\n",
    "\n",
    "    #entity extraction\n",
    "    doc = ner_model(query)\n",
    "    raw_entities = [(ent.label_, ent.text) for ent in doc.ents]\n",
    "    numbers = re.findall(r\"\\b\\d+\\b\", query)\n",
    "    for num in numbers:\n",
    "        raw_entities.append((\"CARDINAL\", num))\n",
    "\n",
    "    query_lower = query.lower()\n",
    "    intent_entity_map = {}\n",
    "\n",
    "    for intent, score in predicted_intents:\n",
    "        if not any(kw in query_lower for kw in intent_keywords[intent]):\n",
    "            continue\n",
    "\n",
    "        expected_labels = intent_to_entity_label.get(intent, [])\n",
    "        found = None\n",
    "        for label, value in raw_entities:\n",
    "            if any(e in label.lower() for e in expected_labels):\n",
    "                found = value\n",
    "                break\n",
    "        if not found:\n",
    "            match = re.search(r\"(person|device|tower|number)\\s+(\\d+)\", query_lower)\n",
    "            if match and any(t in intent for t in match.group(1)):\n",
    "                found = match.group(2)\n",
    "\n",
    "        intent_entity_map[intent] = found\n",
    "\n",
    "    return intent_entity_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0N7Q0w_0ovU5",
    "outputId": "77d781de-ed13-4607-96b8-ac480700423d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified intent: {'get_devices_by_person': '94', 'get_calls_by_person': '94', 'get_phonenumbers_by_person': '94'}\n"
     ]
    }
   ],
   "source": [
    "query = \"devices used by person 94 and phone numbers called\"\n",
    "intent = classify_intents_and_entities(query)\n",
    "print(f\"Identified intent: {intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "A8pSqgPs98sU"
   },
   "outputs": [],
   "source": [
    "#generating data for Spacy - custom NER training\n",
    "persons = [f\"person {i}\" for i in range(1, 50)]\n",
    "devices = [f\"device {i}\" for i in range(1, 20)]\n",
    "phonenumbers = [f\"phonenumber {i}\" for i in range(100, 150)]\n",
    "celltowers = [f\"celltower {i}\" for i in range(20, 40)]\n",
    "dates = [f\"2004-09-{str(i).zfill(2)}\" for i in range(1, 30)]\n",
    "\n",
    "templates = [\n",
    "    (\"Which devices did {person} use?\", [(\"PERSON\", \"person\")]),\n",
    "    (\"What is the phone number used by {person}?\", [(\"PERSON\", \"person\")]),\n",
    "    (\"Show me calls between {phone1} and {phone2}\", [(\"PHONENUMBER\", \"phone1\"), (\"PHONENUMBER\", \"phone2\")]),\n",
    "    (\"List activities for {person}\", [(\"PERSON\", \"person\")]),\n",
    "    (\"Which celltower was used on {date}?\", [(\"DATE\", \"date\")]),\n",
    "    (\"Who used {device}?\", [(\"DEVICE\", \"device\")]),\n",
    "    (\"Which phone numbers were connected to {celltower}?\", [(\"CELLTOWER\", \"celltower\")]),\n",
    "    (\"Did {person} connect to {celltower} on {date}?\", [(\"PERSON\", \"person\"), (\"CELLTOWER\", \"celltower\"), (\"DATE\", \"date\")]),\n",
    "    (\"Between {date1} and {date2}, who used {device}?\", [(\"DATE\", \"date1\"), (\"DATE\", \"date2\"), (\"DEVICE\", \"device\")]),\n",
    "]\n",
    "\n",
    "TRAIN_DATA = []\n",
    "\n",
    "for _ in range(300):\n",
    "    template, entity_labels = random.choice(templates)\n",
    "\n",
    "    phone1 = random.choice(phonenumbers)\n",
    "    phone2 = random.choice([x for x in phonenumbers if x != phone1])\n",
    "\n",
    "    entity_map = {\n",
    "        \"person\": random.choice(persons),\n",
    "        \"device\": random.choice(devices),\n",
    "        \"phone1\": phone1,\n",
    "        \"phone2\": phone2,\n",
    "        \"celltower\": random.choice(celltowers),\n",
    "        \"date\": random.choice(dates),\n",
    "        \"date1\": random.choice(dates),\n",
    "        \"date2\": random.choice(dates),\n",
    "    }\n",
    "\n",
    "    sentence = template.format(**entity_map)\n",
    "\n",
    "    seen_spans = set()\n",
    "    entities = []\n",
    "    for label, key in entity_labels:\n",
    "        val = entity_map[key]\n",
    "        for match in re.finditer(re.escape(val), sentence):\n",
    "            span = (match.start(), match.end(), label)\n",
    "            if span not in seen_spans:\n",
    "                entities.append(span)\n",
    "                seen_spans.add(span)\n",
    "            break\n",
    "\n",
    "    if entities:\n",
    "        TRAIN_DATA.append((sentence, {\"entities\": entities}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXLPaQrTovZn",
    "outputId": "86caaca0-845e-4798-8bf9-b710ea8d4b4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Which phone numbers were connected to celltower 39?',\n",
       "  {'entities': [(38, 50, 'CELLTOWER')]}),\n",
       " ('What is the phone number used by person 16?',\n",
       "  {'entities': [(33, 42, 'PERSON')]}),\n",
       " ('Who used device 18?', {'entities': [(9, 18, 'DEVICE')]}),\n",
       " ('Show me calls between phonenumber 103 and phonenumber 117',\n",
       "  {'entities': [(22, 37, 'PHONENUMBER'), (42, 57, 'PHONENUMBER')]}),\n",
       " ('Between 2004-09-12 and 2004-09-06, who used device 4?',\n",
       "  {'entities': [(8, 18, 'DATE'), (23, 33, 'DATE'), (44, 52, 'DEVICE')]}),\n",
       " ('List activities for person 22', {'entities': [(20, 29, 'PERSON')]}),\n",
       " ('Did person 27 connect to celltower 25 on 2004-09-04?',\n",
       "  {'entities': [(4, 13, 'PERSON'), (25, 37, 'CELLTOWER'), (41, 51, 'DATE')]}),\n",
       " ('Which celltower was used on 2004-09-28?', {'entities': [(28, 38, 'DATE')]}),\n",
       " ('Between 2004-09-21 and 2004-09-06, who used device 19?',\n",
       "  {'entities': [(8, 18, 'DATE'), (23, 33, 'DATE'), (44, 53, 'DEVICE')]}),\n",
       " ('Who used device 4?', {'entities': [(9, 17, 'DEVICE')]})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DM0mMR-_ovce",
    "outputId": "bfdc118e-ba31-4580-fd80-8d140800517d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - Losses: {'ner': np.float32(438.3538)}\n",
      "Iteration 2 - Losses: {'ner': np.float32(0.21570101)}\n",
      "Iteration 3 - Losses: {'ner': np.float32(0.00039316108)}\n",
      "Iteration 4 - Losses: {'ner': np.float32(0.0012614067)}\n",
      "Iteration 5 - Losses: {'ner': np.float32(0.0059129535)}\n",
      "Iteration 6 - Losses: {'ner': np.float32(3.0511909)}\n",
      "Iteration 7 - Losses: {'ner': np.float32(5.945227)}\n",
      "Iteration 8 - Losses: {'ner': np.float32(11.053511)}\n",
      "Iteration 9 - Losses: {'ner': np.float32(6.0718756)}\n",
      "Iteration 10 - Losses: {'ner': np.float32(0.010025921)}\n",
      "Iteration 11 - Losses: {'ner': np.float32(2.9227538)}\n",
      "Iteration 12 - Losses: {'ner': np.float32(1.4020135e-05)}\n",
      "Model saved to custom_ner_model\n"
     ]
    }
   ],
   "source": [
    "#training custom NER model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\")\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(12):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            for text, annotations in batch:\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                nlp.update([example], drop=0.3, losses=losses)\n",
    "        print(f\"Iteration {itn+1} - Losses: {losses}\")\n",
    "\n",
    "output_dir = \"custom_ner_model\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jkZYvocFpyG7",
    "outputId": "c29993e4-2658-4256-cd1a-0fec7bfce736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: [('person 94', 'PERSON'), ('tower 1', 'CELLTOWER'), ('2024-09-04', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "#checking entity extraction from custom ner model\n",
    "nlp = spacy.load(\"custom_ner_model\")\n",
    "text = \"did person 94 connected to tower 1 on 2024-09-04?\"\n",
    "doc = nlp(text)\n",
    "print(\"Entities:\", [(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvovCoYKpyKR",
    "outputId": "cac9cbd1-2d83-4da0-854d-5476c41da7f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: [('phonenumber 2233', 'PHONENUMBER'), ('celltower 26', 'CELLTOWER')]\n"
     ]
    }
   ],
   "source": [
    "text = \"is phonenumber 2233 is from device nokia connected to celltower 26\"\n",
    "doc = nlp(text)\n",
    "print(\"Entities:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443,
     "referenced_widgets": [
      "7dd550cf1d5c4ee5a1f60e21a4fede8d",
      "0a4c025f8775454e8cce7342fdad622c",
      "935084d9ff2547f1942778464f8448a8",
      "9d26ec0588174867850a7c608cd546aa",
      "ab385b00169c40b99f194fe30278977d",
      "46b870bb3779477680af3e9c176c490b",
      "b8667fe35f89407caec70bfc959d6af8",
      "d1847ac320d8436ba1eebcb9811b939c",
      "384d77ac0b0645e5b1e23b0fa54f7830",
      "dcc7e8e3353a42ccaa2941d6efc6298c",
      "65d904f1292a44a1a3c504a8a33ba0c9",
      "0bb2341908c249a68c5f5e0ac90527f9",
      "5b4f156a0eb9436c96293b2dfbf6fd57",
      "bb0db4d4dc5742118763cb6dca39796e",
      "38b33abb504d44b0bb7ce555439971ef",
      "ea70e41c8c3341e280d1d7820da6b17f",
      "d0ff7e426cda457caba9801049329847",
      "27ae93e0927b4b3dbbeab354088ef28d",
      "259327c146f44b5dbb94ac7390d89ea9",
      "cad6dec639664a17a9e00159ffd02634",
      "0cf08191a79a423f93aa8c8cf766bc5b",
      "705cfc60a3b34a6ca5c870220095317b",
      "b9f80f3587f54994a44d2227c5fa4ff1",
      "51a0ac5622fc487ebfb360e6d0a1005c",
      "e8ff0379cb7f40279fe0ddc6620bbd84",
      "07f540435231411a873013c2b7bf13c0",
      "245624a14ebd4681bae27aa252e88d8b",
      "5e6602a727a542d5a00484ec59fa6934",
      "42bb7ef354504a0aa6c20976de23a43b",
      "0f306205a9924387849beec6e52e1679",
      "e102de3071954a9a9424e8952e0ab210",
      "5f09cf6ce4fa4970a2f4d918b0432381",
      "066aefd4e7074ae087149a5bab3f8d30",
      "527af7dd1ade4ef3882e6f22d6817c34",
      "b4c6b7563f9745f1a747b71ac9cc5f5f",
      "cc790987d05a4579b5a3fc24835d24fd",
      "709787cd4c0c43a3a3f18cf2dcc49030",
      "91a0d615d2b54ed3994f0d2c19481e55",
      "30f93143208349ffb09616d3a43e5c6d",
      "f68160fb4bc1406aa86831e2bca4cbb1",
      "7084514e1bf344fda55eb1bdb58290a5",
      "530c5a2084ee4fc0aed4e2a7cd5d90fd",
      "81c84c7cb7fd4097a5ff953dccf756d6",
      "bcdb672723e8425c81de6ac1d75bb9c3",
      "f47843fba61c48f586dec9fdd2862baf",
      "3de17ebce5e04ac788b1a4162791855b",
      "b3707fcc16da4c139de8b7a5142dad66",
      "68d2439418594c5589ca29f56ed29976",
      "f0a7933ba51443b990a7e75042714114",
      "316cb8ed383448e4bc8aaa50d2640e31",
      "0bf8dee9c75f423e9970219ea2358efc",
      "7fe72b6957e944ec9a353fc3ade987dd",
      "8b125ce405e6400a9e6f4fc77e9bc067",
      "4a52839457564125aead8fda2be1e220",
      "d74b7d8e917e4fecb0d4aad73ad3de01",
      "a7845d16072646faa861f68290e2c671",
      "9a59274637b04c56b054f10ce2594ab2",
      "34b38dd411bd4e41b41ea8a2254ceede",
      "6a4266a3b8994be486a65789006f63a1",
      "22c8baa3fd2448f689ff11a8b5087929",
      "e77447d98d2f4ab7a470aa9099539b99",
      "ad6eee54c92e445580ac80c2e9404bb7",
      "e166ca66af4e4784b4639400348037ad",
      "1f63e186bad2457f9c7e403c77f8426d",
      "822e4af5e9b04856a17d8a34b4db23ae",
      "fd41b93e24d840c8a612cf3571aed7aa",
      "62196c94516e4c4da05bc38c26951e15",
      "a8d95a1561b44b87b20832479b0eb5d7",
      "60d798ef786941e39b7b481d59b4fba4",
      "87966ba244f947608147a7ef4d0a9696",
      "801d56258ada45748605352bb3e26e06",
      "3891f3951db74ea2bed02a3eaf44d3b7",
      "401bd082db574844aa03eeef8b81c628",
      "a7f754ae5e9e486abf6a3c7d1673df49",
      "cdd9ea52c58249fca8db7334a0ac74cb",
      "6d6c4656f905493ea815a58d2f200adf",
      "21dfba7f842a46aaa4a9a19819535f3a",
      "2a7f6d0d6e5a434b85a0bfde1cf32c4b",
      "351605a9ad6246e1a820e0930c844d3a",
      "e5077f128a054dd7a636d8dd8863c74a",
      "ff78677cde7b4a94bcbe3b86b6b086d9",
      "a891f7b24d42453baab13e471419afd8",
      "b7949022b9ca4c6fb68b0022507db59d",
      "ec85aca21f9149419c19f98e55197006",
      "fc3310e25b604ce2905b5b52a593bd9c",
      "f2c812e2abf4495b9583281c04f8eada",
      "c53b33280044468c9284647c30fc071f",
      "8b9d4cfde5fb4de49549545c030c1843",
      "f4097460435f42a7984750769f4cf4cd",
      "68742454e7a34f618eb2c59910d50672",
      "691c142aebb64b6baae16d85b1a41a1d",
      "f11a67bca9354212ba70721045978b6e",
      "c59f2d22f43942789cb86046ba198046",
      "9287c917e10540b18dcd3279bcf5f908",
      "2db13528286f4db1a1659864d0a31495",
      "287b1a10223749d58c5332652a993376",
      "9e72cbe4caad44baa6b1951cdfbacee7",
      "c8e38c26edba4b71ba73b0114a571329",
      "48b9cdf44fad4ddf96b8c7c92b0f951d",
      "d8bca873896c43f3ba0eb49c420f3607",
      "53945c998d9d43ebb8851a83778deeda",
      "8a868c9f3ff44b3893f066f19bf94e9b",
      "002dfad07a9a49aa8b5d455a56552173",
      "4949dc0b5e39481791e4910935e98eda",
      "fcf29cdf7ee9422897a1cac84b543d0b",
      "86e9ba9a036947a8a6af9c2bf1e812d1",
      "9736756a99014fc9811dfb4e7dc6023f",
      "0abccc8d99d94bb0b0ca9d27214c7486",
      "19bc9f8e43af4cf888788f1bc5247ba5",
      "815508727b1d4f2eac1225782d4967d3",
      "255d510082fd4d3199f35bf468a549cc",
      "65e6a0afac2a4c998e4794e0b67e976a",
      "7b47132c2c9745f5ae5eeebd84dea207",
      "ab3f21911a38457aa5bd18cb04aa3a2f",
      "239db98edf82441e99883cadd4201344",
      "19d6d74ffa5548499feb02dd9bc4e00c",
      "bbde6200b8d6466cb8a2f9ca21b7b118",
      "c1c9ba795eb24610bba2cccd1fe1633c",
      "4ada894a8ee043e4af4a6b9ecf3463bf",
      "95868976ba3b41a1ae3cdc6d645f86b9",
      "e4cf5924a7be4f0c8b55c218d5da143b"
     ]
    },
    "id": "h64LyRVgmgrk",
    "outputId": "db3bb0a7-b9c0-4011-dd65-96257053a2e8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd550cf1d5c4ee5a1f60e21a4fede8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb2341908c249a68c5f5e0ac90527f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f80f3587f54994a44d2227c5fa4ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527af7dd1ade4ef3882e6f22d6817c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47843fba61c48f586dec9fdd2862baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7845d16072646faa861f68290e2c671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62196c94516e4c4da05bc38c26951e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7f6d0d6e5a434b85a0bfde1cf32c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4097460435f42a7984750769f4cf4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bca873896c43f3ba0eb49c420f3607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255d510082fd4d3199f35bf468a549cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created. Total chunks: 2728\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "all_docs = []\n",
    "all_metadata = []\n",
    "\n",
    "def chunk_text(text, max_words=150):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + max_words]) for i in range(0, len(words), max_words)]\n",
    "\n",
    "with driver.session() as session:\n",
    "\n",
    "    ###Person level Subgraphs\n",
    "    person_query = \"MATCH (p:person) RETURN p.oid AS oid\"\n",
    "    for row in session.run(person_query):\n",
    "        oid = row[\"oid\"]\n",
    "        parts = [f\"Person {oid}\"]\n",
    "\n",
    "        #Including activities\n",
    "        activity_q = \"\"\"\n",
    "            MATCH (p:person {oid: $oid}) RETURN p.activities AS activities\n",
    "        \"\"\"\n",
    "        activity_row = session.run(activity_q, oid=oid).single()\n",
    "        if activity_row and activity_row[\"activities\"]:\n",
    "            activities = activity_row[\"activities\"]\n",
    "            if isinstance(activities, list):\n",
    "                parts.append(\"has activity logs: \" + \"; \".join(str(a) for a in activities))\n",
    "            else:\n",
    "                parts.append(f\"has activity logs: {activities}\")\n",
    "\n",
    "        #device usage\n",
    "        dev_q = \"\"\"\n",
    "            MATCH (p:person {oid: $oid})-[r:USES_DEVICE]->(d:device)\n",
    "            RETURN d.oid AS device, r.starttime AS starttime, r.endtime AS endtime\n",
    "        \"\"\"\n",
    "        for dev in session.run(dev_q, oid=oid):\n",
    "            parts.append(f\"used device {dev['device']} from {dev['starttime']} to {dev['endtime']}.\")\n",
    "\n",
    "        #Multi hop calls\n",
    "        call_q = \"\"\"\n",
    "            MATCH (p:person {oid: $oid})-[:USES_DEVICE]->(d:device)\n",
    "            WITH d.oid AS phone_oid\n",
    "            MATCH (ph:phonenumber {oid: phone_oid})-[:CALLS]->(dst:phonenumber)\n",
    "            RETURN ph.oid AS src, dst.oid AS dst\n",
    "        \"\"\"\n",
    "        for call in session.run(call_q, oid=oid):\n",
    "            parts.append(f\"via phone {call['src']} called {call['dst']}.\")\n",
    "\n",
    "        #Multi hop calls\n",
    "        mob_q = \"\"\"\n",
    "            MATCH (p:person {oid: $oid})-[:USES_DEVICE]->(d:device)\n",
    "            WITH d.oid AS phone_oid\n",
    "            MATCH (ph:phonenumber {oid: phone_oid})-[r:CONNECTED_TO]->(c:celltower)\n",
    "            RETURN c.oid AS celltower, r.starttime AS starttime, r.endtime AS endtime\n",
    "        \"\"\"\n",
    "        for mob in session.run(mob_q, oid=oid):\n",
    "            parts.append(f\"connected to celltower {mob['celltower']} from {mob['starttime']} to {mob['endtime']}.\")\n",
    "\n",
    "        full_text = \" \".join(parts)\n",
    "        chunks = chunk_text(full_text)\n",
    "        all_docs.extend(chunks)\n",
    "        all_metadata.extend([{\"label\": \"person\", \"oid\": oid}] * len(chunks))\n",
    "\n",
    "    ###Device level Subgraphs\n",
    "    device_query = \"MATCH (d:device) RETURN d.oid AS oid\"\n",
    "    for row in session.run(device_query):\n",
    "        oid = row[\"oid\"]\n",
    "        parts = [f\"Device {oid}\"]\n",
    "\n",
    "        usage_q = \"\"\"\n",
    "            MATCH (p:person)-[r:USES_DEVICE]->(d:device {oid: $oid})\n",
    "            RETURN p.oid AS person, r.starttime AS starttime, r.endtime AS endtime\n",
    "        \"\"\"\n",
    "        for usage in session.run(usage_q, oid=oid):\n",
    "            parts.append(f\"was used by person {usage['person']} from {usage['starttime']} to {usage['endtime']}.\")\n",
    "\n",
    "        call_q = \"\"\"\n",
    "            MATCH (ph:phonenumber {oid: $oid})-[:CALLS]->(dst:phonenumber)\n",
    "            RETURN dst.oid AS dst\n",
    "        \"\"\"\n",
    "        for call in session.run(call_q, oid=oid):\n",
    "            parts.append(f\"enabled call to {call['dst']}.\")\n",
    "\n",
    "        tower_q = \"\"\"\n",
    "            MATCH (ph:phonenumber {oid: $oid})-[r:CONNECTED_TO]->(c:celltower)\n",
    "            RETURN c.oid AS celltower, r.starttime AS starttime, r.endtime AS endtime\n",
    "        \"\"\"\n",
    "        for conn in session.run(tower_q, oid=oid):\n",
    "            parts.append(f\"connected to celltower {conn['celltower']} from {conn['starttime']} to {conn['endtime']}.\")\n",
    "\n",
    "        full_text = \" \".join(parts)\n",
    "        chunks = chunk_text(full_text)\n",
    "        all_docs.extend(chunks)\n",
    "        all_metadata.extend([{\"label\": \"device\", \"oid\": oid}] * len(chunks))\n",
    "\n",
    "    ###Phone Number level Subgraphs\n",
    "    phone_query = \"MATCH (ph:phonenumber) RETURN ph.oid AS oid\"\n",
    "    for row in session.run(phone_query):\n",
    "        oid = row[\"oid\"]\n",
    "        parts = [f\"Phone number {oid}\"]\n",
    "\n",
    "        call_q = \"\"\"\n",
    "            MATCH (ph:phonenumber {oid: $oid})-[r:CALLS]->(dst:phonenumber)\n",
    "            RETURN dst.oid AS dst, r.starttime AS starttime, r.endtime AS endtime, r.duration AS duration\n",
    "        \"\"\"\n",
    "        for call in session.run(call_q, oid=oid):\n",
    "            parts.append(f\"called {call['dst']} from {call['starttime']} to {call['endtime']} lasting {call['duration']} seconds.\")\n",
    "\n",
    "        conn_q = \"\"\"\n",
    "            MATCH (ph:phonenumber {oid: $oid})-[r:CONNECTED_TO]->(c:celltower)\n",
    "            RETURN c.oid AS celltower, r.starttime AS starttime, r.endtime AS endtime\n",
    "        \"\"\"\n",
    "        for conn in session.run(conn_q, oid=oid):\n",
    "            parts.append(f\"connected to celltower {conn['celltower']} from {conn['starttime']} to {conn['endtime']}.\")\n",
    "\n",
    "        full_text = \" \".join(parts)\n",
    "        chunks = chunk_text(full_text)\n",
    "        all_docs.extend(chunks)\n",
    "        all_metadata.extend([{\"label\": \"phonenumber\", \"oid\": oid}] * len(chunks))\n",
    "\n",
    "    ###Celltower level Subgraphs\n",
    "    tower_query = \"MATCH (c:celltower) RETURN c.oid AS oid\"\n",
    "    for row in session.run(tower_query):\n",
    "        oid = row[\"oid\"]\n",
    "        parts = [f\"Celltower {oid}\"]\n",
    "\n",
    "        conn_q = \"\"\"\n",
    "            MATCH (ph:phonenumber)-[r:CONNECTED_TO]->(c:celltower {oid: $oid})\n",
    "            RETURN ph.oid AS phonenumber, r.starttime AS starttime, r.endtime AS endtime\n",
    "        \"\"\"\n",
    "        for conn in session.run(conn_q, oid=oid):\n",
    "            parts.append(f\"was connected by phone {conn['phonenumber']} from {conn['starttime']} to {conn['endtime']}.\")\n",
    "\n",
    "        full_text = \" \".join(parts)\n",
    "        chunks = chunk_text(full_text)\n",
    "        all_docs.extend(chunks)\n",
    "        all_metadata.extend([{\"label\": \"celltower\", \"oid\": oid}] * len(chunks))\n",
    "\n",
    "#Embedding documents\n",
    "embeddings = model.encode(all_docs, convert_to_numpy=True)\n",
    "\n",
    "#create and save FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(embeddings)\n",
    "faiss.write_index(faiss_index, \"graph_subgraph_entities.index\")\n",
    "\n",
    "#save chunks and metadata\n",
    "np.save(\"graph_subgraph_entities_texts.npy\", np.array(all_docs))\n",
    "np.save(\"graph_embeddings_all_entities.npy\", embeddings)\n",
    "with open(\"graph_metadata_all_entities.json\", \"w\") as f:\n",
    "    json.dump(all_metadata, f)\n",
    "\n",
    "print(f\"FAISS index created. Total chunks: {len(all_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "b348c6c1370e4952aa7ec38ce5674a75",
      "ebeafbe168a44b619cf691a943e6104b",
      "db0c4b2f99144295a439ee91506e6f91",
      "f42595dba8f241f7bc908e107e54e3db",
      "cea8227e12c34da1bfe9a4c9b76deb0d",
      "932690de7651439ead74299dadcbf27a",
      "8ab47676c7a740fc8c6e00c84b70ad7c",
      "1ce86e4d2adb460bb74a1793ece4b06e",
      "ff46641feb2749f8b3db74dec5e081fe",
      "2234e6058ebc4db4b620277a27080fc8",
      "6a9c240f7f2f4c7d972a63bfc4c347ec",
      "453c4fda806d4e91a4a0d97e9991a3da",
      "9325e81efeba4074906ff69392a6cd7d",
      "1d41ad7bb01246ea8b83a41d772b205d",
      "9fb66d81ed584762a6d1af54b2b27f6f",
      "b6773fb1519c435eb0d84aed2e6789b3",
      "1241a86f3d294604a64d58914137e87c",
      "3debb16327194fd0981e2ddec63e6dd7",
      "1219defa67aa4a5c917d456c94f02de4",
      "2bc2589701494d1180e8f23e6d95ce67",
      "e3a33b1b175e44ecab902f97ca837368",
      "140dc2dbef6a47b0a63a111ad6dcc017",
      "2d280562a2834906a1baa56e42d24e19",
      "48f5f2567d7a406d866ad270da3021a4",
      "3fc6e32064b1489da878807430f10e64",
      "5e0b51fae32f480780322c5ef4577546",
      "21779ddf673748f6b48ee4ce36af1f6b",
      "1b166f79a0734417b062fc92d1283d46",
      "31c9a9b97f8341caa4c6407c23f31147",
      "857d401f3b2f4bc4a5e4929ae41b99cd",
      "e328fbe364714fd79856d17129e0345c",
      "9a23d38c0e894ffdaaff50dcbb51dc82",
      "df49d402b1e945528cedbb2b5af01e91",
      "ce427de9970f43e3a886baa732714131",
      "45bc9d96d99d417789b46f991d37c5f2",
      "9d130c94780249ac8fa17717f388396d",
      "c0d41c2b6e604cc3bae2fc7f344a07bb",
      "2be7476edbaf4b1da029d7eaa0952985",
      "2fb29f4d7fcc4911bc89b803ec068ab4",
      "44fee8dc228d404f8a740c25535f8aae",
      "363190ac3b76422eadc73381c2a82472",
      "0b1611f6d83149169a60188c9f9e53c4",
      "46bb462686d442078fca1f33b80a0c24",
      "6880025b0e904128b97ae3be494805df",
      "45c1ca8b61c44d37a004261568d3eba2",
      "dda0a8d0b18b4bfab4dcd38a09b7824a",
      "fdeaa787d53c4c3daa8739f5f442fd39",
      "61844a24a6c54ab39e315a8dec5c8e53",
      "e804ba8503bf431fb5a7ed2c5965687e",
      "6d9b763d178d4a5ca274c5691bcf1f59",
      "794a3a1d9a8c4948865fd4b3632848a4",
      "7cc1c2d0c8314efa941d493c76b4d502",
      "ab668fae323c4e5da9fcbf308caca25d",
      "6791ecf5e4d34d0dbc614fe80bf34bc5",
      "672d65c088224db4a8ed99401ed5b9e8",
      "583c0525c18c44fbafbc5cd4abeab5dc",
      "dc3247ff90714d8eae42bfaa4fd6f84a",
      "80cf8eac97214045ab8f7d2b51d0e80b",
      "fd25cf6c57d94a9caa94fe39c7613825",
      "58eb8592b08f420eafd6130342e0452a",
      "ebd68e0bc46e4d8bb596f64c47a35945",
      "c70f21da34f9418a9e17e13546bd9ddc",
      "ab836e224c6047dbba231822e9745938",
      "319767936004445995dce73ea4140aa2",
      "543f0e00b54e45a89797b9c55ea4e63b",
      "4ebda7f7b02a4d0a8cf7e9ae152e3355",
      "671f63a14ef64c4b8c1d03caed275ba3",
      "8855d5fe22e14d3d82a85e11a6b02a50",
      "bc8620a8bb9442bc81677dfcf55ef40e",
      "81f46500352f42cfb8e7943b165be2e4",
      "1c77392c6988410bbccca5eb0e3db854",
      "d6de69ab8e4c4906a9d38d387555393f",
      "faf5e1c98dbe451ebc3e1c44e0893ff3",
      "dc3cc59220ef462d937952b4deb5dc26",
      "d57eaa4cf3c94f28a31b81a081d5ddd8",
      "d98b0a5c6c4c4a6b9571af56b43d4d4d",
      "b5d160d0c7b9426584ce894c8f556e30"
     ]
    },
    "id": "TZTkI1ocdLLn",
    "outputId": "0ea4029d-7b44-4cec-c033-7d1cbbf6b64a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b348c6c1370e4952aa7ec38ce5674a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453c4fda806d4e91a4a0d97e9991a3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d280562a2834906a1baa56e42d24e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce427de9970f43e3a886baa732714131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c1ca8b61c44d37a004261568d3eba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583c0525c18c44fbafbc5cd4abeab5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671f63a14ef64c4b8c1d03caed275ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LLM for cypher generation\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "\n",
    "#Embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "#Load FAISS index\n",
    "faiss_index = faiss.read_index(\"graph_subgraph_entities.index\")\n",
    "with open(\"graph_subgraph_entities_texts.npy\", \"rb\") as f:\n",
    "    all_docs = np.load(f, allow_pickle=True).tolist()\n",
    "with open(\"graph_metadata_all_entities.json\", \"r\") as f:\n",
    "    all_metadata = json.load(f)\n",
    "\n",
    "assert len(all_docs) == faiss_index.ntotal == len(all_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gh8p848QbROe"
   },
   "outputs": [],
   "source": [
    "#query embedding\n",
    "def get_query_embedding(query):\n",
    "    return embedding_model.encode([query]).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HFviVDJfrDY4"
   },
   "outputs": [],
   "source": [
    "def search_faiss_index(query_embedding, top_k=20, entity_filter=None, faiss_k=50):\n",
    "    distances, indices = faiss_index.search(query_embedding, faiss_k)\n",
    "    retrieved_docs = [all_docs[i] for i in indices[0]]\n",
    "    retrieved_meta = [all_metadata[i] for i in indices[0]]\n",
    "\n",
    "    candidates = list(zip(retrieved_docs, retrieved_meta))\n",
    "\n",
    "    if entity_filter:\n",
    "        extended_filters = set()\n",
    "        if isinstance(entity_filter, dict):\n",
    "            for label, value in entity_filter.items():\n",
    "                extended_filters.add(str(value).lower())\n",
    "                extended_filters.add(f\"{label.lower()} {value}\".lower())\n",
    "        elif isinstance(entity_filter, list):\n",
    "            extended_filters = set(str(v).lower() for v in entity_filter)\n",
    "\n",
    "        def relevance_score(doc):\n",
    "            score = 0\n",
    "            doc_lower = doc.lower()\n",
    "            for f in extended_filters:\n",
    "                if f in doc_lower:\n",
    "                    score += 5 if ' ' in f else 2\n",
    "            return score\n",
    "\n",
    "        #keeping only non 0 relevance score\n",
    "        filtered = [(doc, meta) for doc, meta in candidates if relevance_score(doc) > 0]\n",
    "        filtered_sorted = sorted(filtered, key=lambda x: relevance_score(x[0]), reverse=True)\n",
    "        return filtered_sorted[:top_k] if filtered_sorted else candidates[:top_k]\n",
    "\n",
    "    return candidates[:top_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mT40Oz2vrDbd"
   },
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entity_dict = {}\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ not in entity_dict:\n",
    "            entity_dict[ent.label_] = ent.text.strip()\n",
    "        else:\n",
    "            if isinstance(entity_dict[ent.label_], list):\n",
    "                entity_dict[ent.label_].append(ent.text.strip())\n",
    "            else:\n",
    "                entity_dict[ent.label_] = [entity_dict[ent.label_], ent.text.strip()]\n",
    "    return entity_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nGcSf37JqwmS"
   },
   "outputs": [],
   "source": [
    "def generate_cypher_query(query, intent, entities, docs):\n",
    "    examples = \"\"\"\n",
    "Example 1:\n",
    "Query: Which devices did person 123 use?\n",
    "Intent: get_devices_by_person\n",
    "Entities: PERSON=123\n",
    "Graph context:\n",
    "- person 123 used device 10 from 2004-09-01 to 2004-09-10\n",
    "- person 123 used device 12 from 2004-09-11 to 2004-09-12\n",
    "Cypher:\n",
    "MATCH (p:person {oid: '123'})-[r:USES_DEVICE]->(d:device)\n",
    "RETURN d.oid AS device_id, r.starttime, r.endtime\n",
    "\n",
    "Example 2:\n",
    "Query: What phone numbers did person 456 call?\n",
    "Intent: get_calls_by_person\n",
    "Entities: PERSON=456\n",
    "Graph context:\n",
    "- person 456 called phonenumber 789 from 2004-09-01 to 2004-09-10\n",
    "Cypher:\n",
    "MATCH (p:person {oid: '456'})-[r:CALLS]->(ph:phonenumber)\n",
    "RETURN ph.oid AS phonenumber, r.starttime, r.endtime, r.duration\n",
    "\n",
    "Example 3:\n",
    "Query: What activities are logged for person 789?\n",
    "Intent: get_activities_by_person\n",
    "Entities: PERSON=789\n",
    "Graph context:\n",
    "- person 789 has recorded activities between 2004-09-05 and 2004-09-08\n",
    "Cypher:\n",
    "MATCH (p:person {oid: '789'})\n",
    "RETURN p.activities\n",
    "\n",
    "Example 4:\n",
    "Query: How many devices did person 94 use?\n",
    "Intent: count_devices_by_person\n",
    "Entities: PERSON=94\n",
    "Graph context:\n",
    "- person 94 used device 5 from 2004-09-01 to 2004-09-10\n",
    "Cypher:\n",
    "MATCH (p:person {oid: '94'})-[:USES_DEVICE]->(d:device)\n",
    "RETURN COUNT(d) AS device_count\n",
    "\n",
    "Example 5:\n",
    "Query: What cell towers was person 321 connected to?\n",
    "Intent: get_celltowers_by_person\n",
    "Entities: PERSON=321\n",
    "Graph context:\n",
    "- person 321 was connected to celltower A from 2004-09-03 to 2004-09-04\n",
    "- person 321 was connected to celltower B from 2004-09-05 to 2004-09-06\n",
    "Cypher:\n",
    "MATCH (p:person {oid: '321'})-[r:CONNECTED_TO]->(ct:celltower)\n",
    "RETURN ct.oid AS celltower_id, r.starttime, r.endtime\n",
    "\"\"\"\n",
    "\n",
    "    facts = \"\\n\".join(f\"- {d}\" for d, _ in docs[:5])\n",
    "    normalized_entities = {k: v.split()[-1] for k, v in entities.items()}\n",
    "    entity_context = \", \".join([f\"{k}={v}\" for k, v in normalized_entities.items()])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a Neo4j Cypher expert. Given a user query, its mapped intent, extracted entities, and relevant graph facts, your task is to generate a valid and optimized Cypher query.\n",
    "\n",
    "### SCHEMA DEFINITION ###\n",
    "Node Labels:\n",
    "- person\n",
    "- device\n",
    "- phonenumber\n",
    "- celltower\n",
    "\n",
    "Relationship Types:\n",
    "- USES_DEVICE\n",
    "- CALLS\n",
    "- CONNECTED_TO\n",
    "\n",
    "Node Properties:\n",
    "- person: oid, activities\n",
    "- device: oid\n",
    "- phonenumber: oid\n",
    "- celltower: oid\n",
    "\n",
    "Relationship Properties:\n",
    "- USES_DEVICE: starttime, endtime\n",
    "- CALLS: starttime, endtime, duration\n",
    "- CONNECTED_TO: starttime, endtime\n",
    "\n",
    "Use exact property and label names. If a relationship includes time information (e.g., starttime, endtime), include it in the `RETURN` clause when relevant. When referring to a person's activities, use `p.activities`.\n",
    "\n",
    "{examples}\n",
    "\n",
    "### NEW QUERY ###\n",
    "Query: {query}\n",
    "Intent: {intent}\n",
    "Entities: {entity_context}\n",
    "Graph context:\n",
    "{facts}\n",
    "Cypher:\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    #attention_mask = attention_mask.to(model.device)\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        #attention_mask=attention_mask,\n",
    "        #temperature=0.5,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    if \"Cypher:\" in decoded:\n",
    "        decoded = decoded.split(\"Cypher:\")[-1].strip()\n",
    "\n",
    "    cypher_lines = decoded.splitlines()\n",
    "    for i, line in enumerate(cypher_lines):\n",
    "        if \"MATCH\" in line:\n",
    "            return \"\\n\".join(cypher_lines[i:]).strip()\n",
    "\n",
    "    return decoded.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_HfNJ3mq3bD"
   },
   "outputs": [],
   "source": [
    "query = \"which tower is used highly by person 94\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "IZkO5LdY5IHO"
   },
   "outputs": [],
   "source": [
    "query =\"what activities were logged for person 94\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgApJVK7u4Rm",
    "outputId": "c18e2dcd-29e8-4bcd-8900-6049ecbe4b42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'get_activities_by_person': '94'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent = classify_intents_and_entities(query)\n",
    "intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dotAY7vq3e-",
    "outputId": "05d1c523-2d48-4fb1-f1d7-19f104fbd7e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PERSON': 'person 94'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = extract_entities(query)\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dEaUFkawq94E"
   },
   "outputs": [],
   "source": [
    "query_embedding = get_query_embedding(query)\n",
    "#query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ptNvcm7Sq96W"
   },
   "outputs": [],
   "source": [
    "context = search_faiss_index(query_embedding, top_k=20,entity_filter=entities)\n",
    "#context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_CegEHI3Djw",
    "outputId": "53fb8d5d-47d4-4b2d-a027-842f3a5521c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Device 184 was used by person 94 from 2004-09-29T14:02:52 to 2004-09-29T14:02:52.',\n",
       "  {'label': 'device', 'oid': 184}),\n",
       " ('Device 839 was used by person 94 from 2005-03-26T14:20:00 to 2005-03-26T14:25:12.',\n",
       "  {'label': 'device', 'oid': 839}),\n",
       " ('used by person 94 from 2005-01-21T13:29:25 to 2005-01-21T14:19:17. was used by person 94 from 2005-02-28T16:08:04 to 2005-02-28T16:08:04.',\n",
       "  {'label': 'device', 'oid': 35}),\n",
       " ('Device 199 was used by person 94 from 2004-10-03T13:31:16 to 2004-10-03T13:31:16.',\n",
       "  {'label': 'device', 'oid': 199}),\n",
       " ('Device 729 was used by person 94 from 2005-02-21T11:31:45 to 2005-02-21T11:31:45.',\n",
       "  {'label': 'device', 'oid': 729}),\n",
       " ('Device 174 was used by person 94 from 2004-09-20T16:06:35 to 2004-09-20T16:22:14. was used by person 94 from 2004-09-20T17:35:22 to 2004-09-20T17:46:11. was used by person 94 from 2004-10-25T16:13:18 to 2004-10-25T16:13:18. was used by person 94 from 2004-11-01T16:07:35 to 2004-11-01T16:23:15. was used by person 94 from 2004-11-01T17:05:14 to 2004-11-01T17:47:21. was used by person 94 from 2004-11-08T16:12:18 to 2004-11-08T16:43:41. was used by person 94 from 2004-11-15T16:09:43 to 2004-11-15T16:09:43. was used by person 94 from 2004-12-06T16:16:04 to 2004-12-06T16:31:43. was used by person 94 from 2004-12-06T16:41:40 to 2004-12-06T17:49:36.',\n",
       "  {'label': 'device', 'oid': 174}),\n",
       " ('Device 195 was used by person 94 from 2004-10-02T14:56:55 to 2004-10-02T14:56:55.',\n",
       "  {'label': 'device', 'oid': 195}),\n",
       " ('Device 799 was used by person 94 from 2005-02-28T12:26:25 to 2005-02-28T12:31:38.',\n",
       "  {'label': 'device', 'oid': 799}),\n",
       " ('Device 769 was used by person 94 from 2005-02-21T13:18:35 to 2005-02-21T13:18:35.',\n",
       "  {'label': 'device', 'oid': 769}),\n",
       " ('Device 659 was used by person 94 from 2005-02-15T15:25:33 to 2005-02-15T15:37:57.',\n",
       "  {'label': 'device', 'oid': 659}),\n",
       " ('94 from 2004-09-10T19:59:32 to 2004-09-10T19:59:32. was used by person 94 from 2004-11-23T11:09:42 to 2004-11-23T15:52:25. was used by person 94 from 2004-09-10T23:01:47 to 2004-09-11T01:17:39. was used by person 94 from 2004-11-23T16:29:17 to 2004-11-23T19:48:30. was used by person 94 from 2004-09-11T08:09:22 to 2004-09-11T09:01:36. was used by person 94 from 2004-11-23T22:04:13 to 2004-11-23T22:04:13. was used by person 94 from 2004-11-24T08:25:26 to 2004-11-24T08:36:05. was used by person 94 from 2004-09-11T11:33:01 to 2004-09-11T11:33:01. was used by person 94 from 2004-11-24T09:23:41 to 2004-11-24T09:23:41. was used by person 94 from 2004-09-11T17:07:05 to 2004-09-11T17:07:05. was used by person 94 from 2004-11-24T10:10:42 to 2004-11-24T10:10:42. was used by person 94 from 2004-09-11T22:51:27 to 2004-09-11T22:51:27. was used by person 94 from 2004-11-24T10:36:54 to 2004-11-24T11:29:26. was used by person 94 from 2004-09-12T04:09:11 to 2004-09-12T04:09:11. was used by person 94 from 2004-11-24T12:06:16 to 2004-11-24T12:37:56. was used by person 94 from 2004-09-12T16:40:40 to 2004-09-12T16:40:40. was used by person 94 from 2004-11-24T18:48:58 to 2004-11-24T18:48:58. was',\n",
       "  {'label': 'device', 'oid': 15}),\n",
       " ('94 from 2004-11-08T09:36:55 to 2004-11-08T09:36:55. was used by person 94 from 2004-11-08T15:14:37 to 2004-11-08T15:14:37. was used by person 94 from 2004-11-09T10:24:42 to 2004-11-09T10:24:42. was used by person 94 from 2004-11-09T16:07:23 to 2004-11-09T16:07:23. was used by person 94 from 2004-11-15T09:32:28 to 2004-11-15T09:53:36. was used by person 94 from 2004-11-16T10:43:23 to 2004-11-16T10:43:23. was used by person 94 from 2004-11-16T15:17:59 to 2004-11-16T15:49:28. was used by person 94 from 2004-11-17T10:39:05 to 2004-11-17T10:39:05. was used by person 94 from 2004-11-18T17:37:22 to 2004-11-18T17:37:22. was used by person 94 from 2004-11-22T09:35:44 to 2004-11-22T09:46:29. was used by person 94 from 2004-11-30T10:08:45 to 2004-11-30T10:08:45. was used by person 94 from 2004-11-30T16:01:04 to 2004-11-30T16:01:04. was used by person 94 from 2004-12-01T17:07:19 to 2004-12-01T17:07:19. was used by person 94 from 2004-12-03T10:09:30 to 2004-12-03T10:09:30. was used by person 94 from 2004-12-03T15:57:41 to 2004-12-03T15:57:41. was used by person 94 from 2004-12-07T10:10:40 to 2004-12-07T10:10:40. was used by person 94 from 2004-12-07T16:01:32 to 2004-12-07T16:22:38. was',\n",
       "  {'label': 'device', 'oid': 220}),\n",
       " ('Device 198 was used by person 94 from 2004-10-03T13:10:13 to 2004-10-03T13:10:13.',\n",
       "  {'label': 'device', 'oid': 198}),\n",
       " ('Device 214 was used by person 94 from 2004-10-03T17:19:17 to 2004-10-03T17:19:17.',\n",
       "  {'label': 'device', 'oid': 214}),\n",
       " ('used by person 94 from 2004-11-13T15:48:25 to 2004-11-13T15:48:25. was used by person 94 from 2004-11-13T16:57:02 to 2004-11-13T16:57:02. was used by person 94 from 2004-11-13T20:21:03 to 2004-11-13T20:21:03. was used by person 94 from 2004-11-14T07:49:34 to 2004-11-14T07:49:34. was used by person 94 from 2004-09-10T10:17:11 to 2004-09-10T13:06:01. was used by person 94 from 2004-11-14T15:09:58 to 2004-11-14T20:23:20. was used by person 94 from 2004-11-15T05:06:16 to 2004-11-15T05:06:16. was used by person 94 from 2004-11-15T10:19:47 to 2004-11-15T10:19:47. was used by person 94 from 2004-11-15T18:16:21 to 2004-11-15T18:26:54. was used by person 94 from 2004-11-16T12:20:08 to 2004-11-16T12:46:22. was used by person 94 from 2004-11-16T19:07:53 to 2004-11-16T19:07:53. was used by person 94 from 2004-11-16T21:44:26 to 2004-11-16T21:44:26. was used by person 94 from 2004-11-16T23:55:09 to 2004-11-16T23:55:09. was used by person 94 from 2004-11-17T09:52:01 to 2004-11-17T09:52:01. was used by person 94 from 2004-09-10T15:57:05 to 2004-09-10T16:02:19. was used by person 94 from 2004-11-17T16:50:21 to 2004-11-17T16:55:33. was used by person 94 from 2004-11-17T17:32:03',\n",
       "  {'label': 'device', 'oid': 15}),\n",
       " ('Device 739 was used by person 94 from 2005-02-21T11:46:30 to 2005-02-21T11:46:30.',\n",
       "  {'label': 'device', 'oid': 739}),\n",
       " ('94 from 2004-11-01T14:48:46 to 2004-11-01T14:48:46. was used by person 94 from 2004-11-04T11:24:43 to 2004-11-04T17:03:15. was used by person 94 from 2004-11-05T12:38:56 to 2004-11-05T13:00:08. was used by person 94 from 2004-11-08T12:51:39 to 2004-11-08T15:03:43. was used by person 94 from 2004-11-09T15:14:27 to 2004-11-09T15:46:28. was used by person 94 from 2004-11-12T14:25:10 to 2004-11-12T14:30:46. was used by person 94 from 2004-11-12T15:39:19 to 2004-11-12T16:53:24. was used by person 94 from 2004-11-19T17:47:18 to 2004-11-19T18:39:32. was used by person 94 from 2004-11-22T13:26:50 to 2004-11-22T13:53:23. was used by person 94 from 2004-11-29T12:35:28 to 2004-11-29T14:20:36. was used by person 94 from 2004-11-30T10:50:38 to 2004-11-30T11:27:16. was used by person 94 from 2004-11-30T13:08:17 to 2004-11-30T15:50:25. was used by person 94 from 2004-12-01T12:42:14 to 2004-12-01T16:04:47. was used by person 94 from 2004-12-01T16:14:33 to 2004-12-01T16:56:35. was used by person 94 from 2004-12-02T09:31:11 to 2004-12-02T16:02:23. was used by person 94 from 2004-12-03T11:53:56 to 2004-12-03T12:41:10. was used by person 94 from 2004-12-03T13:02:15 to 2004-12-03T13:17:56. was',\n",
       "  {'label': 'device', 'oid': 2}),\n",
       " ('94 from 2004-11-01T14:48:46 to 2004-11-01T14:48:46. was used by person 94 from 2004-11-04T11:56:25 to 2004-11-04T12:49:01. was used by person 94 from 2004-11-04T14:08:17 to 2004-11-04T16:52:22. was used by person 94 from 2004-11-05T11:51:29 to 2004-11-05T13:00:08. was used by person 94 from 2004-11-17T10:45:22 to 2004-11-17T15:51:54. was used by person 94 from 2004-11-17T16:23:30 to 2004-11-17T16:39:22. was used by person 94 from 2004-11-19T16:02:32 to 2004-11-19T17:25:59. was used by person 94 from 2004-11-19T18:03:02 to 2004-11-19T18:39:32. was used by person 94 from 2004-11-22T12:49:37 to 2004-11-22T13:05:37. was used by person 94 from 2004-11-22T13:53:23 to 2004-11-22T13:53:23. was used by person 94 from 2004-11-22T15:40:47 to 2004-11-22T16:09:09. was used by person 94 from 2004-11-29T12:35:28 to 2004-11-29T14:20:36. was used by person 94 from 2004-11-30T15:19:08 to 2004-11-30T15:50:25. was used by person 94 from 2004-12-01T11:49:20 to 2004-12-01T13:09:01. was used by person 94 from 2005-01-11T13:09:20 to 2005-01-11T16:51:19. was used by person 94 from 2005-01-12T10:56:22 to 2005-01-12T12:00:02. was used by person 94 from 2005-01-12T12:08:19 to 2005-01-12T12:24:20. was',\n",
       "  {'label': 'device', 'oid': 87}),\n",
       " ('Device 189 was used by person 94 from 2004-09-30T13:14:27 to 2004-09-30T13:14:27.',\n",
       "  {'label': 'device', 'oid': 189}),\n",
       " ('Device 229 was used by person 94 from 2004-10-11T13:01:44 to 2004-10-11T13:01:44.',\n",
       "  {'label': 'device', 'oid': 229})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ZiSPcoK3q989"
   },
   "outputs": [],
   "source": [
    "cypher_query = generate_cypher_query(query, intent, entities, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "778W7mFrq3iC",
    "outputId": "062c9ca2-69ef-49ab-e753-82ec3a656b97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Cypher:\n",
      "MATCH (p:person {oid: '94'})-[:USES_DEVICE]->(d:device)\n",
      "-> (f:activity {startime: $start_time, endtime: $end_time})\n",
      "RETURN f\n",
      "\n",
      "Notice that there are no use cases with an `IF` statement. We will add those with a future refactor. This query is now a bit shorter.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nGenerated Cypher:\\n{cypher_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYOqaJht8xOm",
    "outputId": "9120531e-f37c-4785-bb48-c3e18ef40d8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvRyqAMW9HAp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
